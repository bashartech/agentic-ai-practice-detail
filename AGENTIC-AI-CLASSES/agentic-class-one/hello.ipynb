{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4526c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e267162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salam! How can I help you?\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig\n",
    "\n",
    "external_client = AsyncOpenAI(\n",
    "   api_key=gemini_api_key,\n",
    "   base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\" \n",
    ")\n",
    "\n",
    "model = OpenAIChatCompletionsModel(\n",
    "    model= \"gemini-2.0-flash\",\n",
    "    openai_client= external_client\n",
    ")\n",
    "\n",
    "config = RunConfig(\n",
    "    model= model,\n",
    "    model_provider= external_client,\n",
    "    tracing_disabled= True\n",
    ")\n",
    "\n",
    "greeting_agent = Agent(\n",
    "    name = \"Greeting Agent\",\n",
    "    instructions=\"You are a greeting agent and your is to salam (How can I help you), when someone says hello, hi\"\n",
    "    ,  \n",
    ")\n",
    "\n",
    "agent_result= await Runner.run(\n",
    "   greeting_agent, \n",
    "   \"Hello\",\n",
    "   run_config= config\n",
    "    )\n",
    "agent_result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9881eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     34\u001b[39m     servings: \u001b[38;5;28mint\u001b[39m\n\u001b[32m     36\u001b[39m recipe_agent = Agent(\n\u001b[32m     37\u001b[39m     name = \u001b[33m\"\u001b[39m\u001b[33mRecipe Agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     instructions= (\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     output_type= Recipe\n\u001b[32m     44\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m Runner.run(\n\u001b[32m     47\u001b[39m     recipe_agent,\n\u001b[32m     48\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mItalian Sasuage with Spaghetti \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m response.final_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\run.py:219\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[39m\n\u001b[32m    214\u001b[39m logger.debug(\n\u001b[32m    215\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     input_guardrail_results, turn_result = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    220\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_input_guardrails(\n\u001b[32m    221\u001b[39m             starting_agent,\n\u001b[32m    222\u001b[39m             starting_agent.input_guardrails\n\u001b[32m    223\u001b[39m             + (run_config.input_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[32m    224\u001b[39m             copy.deepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[32m    225\u001b[39m             context_wrapper,\n\u001b[32m    226\u001b[39m         ),\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    228\u001b[39m             agent=current_agent,\n\u001b[32m    229\u001b[39m             all_tools=all_tools,\n\u001b[32m    230\u001b[39m             original_input=original_input,\n\u001b[32m    231\u001b[39m             generated_items=generated_items,\n\u001b[32m    232\u001b[39m             hooks=hooks,\n\u001b[32m    233\u001b[39m             context_wrapper=context_wrapper,\n\u001b[32m    234\u001b[39m             run_config=run_config,\n\u001b[32m    235\u001b[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001b[32m    236\u001b[39m             tool_use_tracker=tool_use_tracker,\n\u001b[32m    237\u001b[39m             previous_response_id=previous_response_id,\n\u001b[32m    238\u001b[39m         ),\n\u001b[32m    239\u001b[39m     )\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    241\u001b[39m     turn_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._run_single_turn(\n\u001b[32m    242\u001b[39m         agent=current_agent,\n\u001b[32m    243\u001b[39m         all_tools=all_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m         previous_response_id=previous_response_id,\n\u001b[32m    252\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\run.py:787\u001b[39m, in \u001b[36mRunner._run_single_turn\u001b[39m\u001b[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;28minput\u001b[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001b[32m    785\u001b[39m \u001b[38;5;28minput\u001b[39m.extend([generated_item.to_input_item() \u001b[38;5;28;01mfor\u001b[39;00m generated_item \u001b[38;5;129;01min\u001b[39;00m generated_items])\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m new_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_new_response(\n\u001b[32m    788\u001b[39m     agent,\n\u001b[32m    789\u001b[39m     system_prompt,\n\u001b[32m    790\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    791\u001b[39m     output_schema,\n\u001b[32m    792\u001b[39m     all_tools,\n\u001b[32m    793\u001b[39m     handoffs,\n\u001b[32m    794\u001b[39m     context_wrapper,\n\u001b[32m    795\u001b[39m     run_config,\n\u001b[32m    796\u001b[39m     tool_use_tracker,\n\u001b[32m    797\u001b[39m     previous_response_id,\n\u001b[32m    798\u001b[39m )\n\u001b[32m    800\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._get_single_step_result_from_response(\n\u001b[32m    801\u001b[39m     agent=agent,\n\u001b[32m    802\u001b[39m     original_input=original_input,\n\u001b[32m   (...)\u001b[39m\u001b[32m    811\u001b[39m     tool_use_tracker=tool_use_tracker,\n\u001b[32m    812\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\run.py:942\u001b[39m, in \u001b[36mRunner._get_new_response\u001b[39m\u001b[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_new_response\u001b[39m(\n\u001b[32m    930\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m     previous_response_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    941\u001b[39m ) -> ModelResponse:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     model = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m     model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001b[32m    944\u001b[39m     model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\run.py:997\u001b[39m, in \u001b[36mRunner._get_model\u001b[39m\u001b[34m(cls, agent, run_config)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agent.model, Model):\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m agent.model\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\models\\multi_provider.py:144\u001b[39m, in \u001b[36mMultiProvider.get_model\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m provider.get_model(model_name)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_fallback_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\models\\openai_provider.py:85\u001b[39m, in \u001b[36mOpenAIProvider.get_model\u001b[39m\u001b[34m(self, model_name)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     83\u001b[39m     model_name = DEFAULT_MODEL\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     88\u001b[39m     OpenAIResponsesModel(model=model_name, openai_client=client)\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_responses\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m OpenAIChatCompletionsModel(model=model_name, openai_client=client)\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\agents\\models\\openai_provider.py:71\u001b[39m, in \u001b[36mOpenAIProvider._get_client\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> AsyncOpenAI:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m         \u001b[38;5;28mself\u001b[39m._client = _openai_shared.get_default_openai_client() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stored_api_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_openai_shared\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_default_openai_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stored_base_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stored_organization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stored_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshared_http_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AAA\\OneDrive\\PYTHON\\quarter-4\\agentic-ai-5\\venv\\Lib\\site-packages\\openai\\_client.py:427\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    425\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    428\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m     )\n\u001b[32m    430\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, RunConfig\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
    "\n",
    "\n",
    "external_client = AsyncOpenAI(\n",
    "   api_key=gemini_api_key,\n",
    "   base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\" \n",
    ")\n",
    "\n",
    "model = OpenAIChatCompletionsModel(\n",
    "    model= \"gemini-2.0-flash\",\n",
    "    openai_client= external_client\n",
    ")\n",
    "\n",
    "config = RunConfig(\n",
    "    model= model,\n",
    "    model_provider= external_client,\n",
    "    tracing_disabled= True\n",
    ")\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    ingrediants: list[str]\n",
    "    cooking_item: int #in  \n",
    "    servings: int\n",
    "\n",
    "recipe_agent = Agent(\n",
    "    name = \"Recipe Agent\",\n",
    "    instructions= (\"\"\"\n",
    "                   You are an agent for creating recipes. You will be given the name of a food and your job\n",
    "                   is to output that as an actual detailed recipe. The cooking time should be in minutes. \n",
    "                   \"\"\"),\n",
    "\n",
    "    output_type= Recipe\n",
    ")\n",
    "\n",
    "response = await Runner.run(\n",
    "    recipe_agent,\n",
    "   \"Italian Sasuage with Spaghetti \")\n",
    "response.final_output\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
